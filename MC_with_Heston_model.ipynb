{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Hedged Monte Carlo\n",
    "\n",
    "Author: Jerry Xia\n",
    "\n",
    "Date: 2018/06/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "This is a Python Notebook about variance reduction Monte Carlo simulations. In this script, I implemented the following variance reduction methods as well as their antithetic variates' version:\n",
    "\n",
    "* regular Monte Carlo\n",
    "* Monte Carlo with delta-based control variates\n",
    "* optimal hedged Monte Carlo\n",
    "\n",
    "Due to the significance and robustness, I mainly focus on the optimal hedged Monte Carlo (OHMC) in option pricing. We invoke this method to price European options and make comparison with other methods.\n",
    "\n",
    "### 1.1 Facts\n",
    "* The option price is not simply the average value of the discounted future pay-off over the objective (or historical) probability distribution\n",
    "* The requirement of absence of arbitrage opportunities is equivalent to the existence of \"risk-neutral measure\", such that the price is indeed its average discounted future pay-off.\n",
    "* Risk in option trading cannot be eliminated\n",
    "\n",
    "### 1.2 Objective\n",
    "* It would be satisfactory to have an option theory where the objective stochastic process of the underlying is used to calculate the option price, the hedge strategy and the *residual risk*.\n",
    "\n",
    "### 1.3 Advantages\n",
    "* It is a versatile methods to price complicated path-dependent options.\n",
    "* Considerable variance reduction scheme for Monte Carlo\n",
    "* It provide not only a numerical estimate of the option price, but also of the optimal hedge strategy and of the residual risk.\n",
    "* This method does not rely on the notion of risk-neutral measure, and can be used to any model of the true dynamics of the underlying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Underlying dynamics\n",
    "\n",
    "### Black-Scholes Model\n",
    "$$dS = \\mu S dt + \\sigma S dW_t$$\n",
    "$$log S_{t+1} = log S_t +(\\mu - \\frac{\\sigma^2}{2})\\Delta t + \\sigma \\sqrt{\\Delta t} \\epsilon$$\n",
    "where\n",
    "$$\\epsilon \\sim N(0,1)$$\n",
    "In risk neutral measure, $\\mu = r - q$. \n",
    "### Heston Model\n",
    "The basic Heston model assumes that $S_t$, the price of the asset, is determined by a stochastic process:\n",
    "$$\n",
    "dS_t = \\mu S_t dt + \\sqrt{v_t} S_t d W_t^S\\\\\n",
    "dv_t = \\kappa (\\theta - v_t) dt + \\xi \\sqrt{v_t} d W_t^v\n",
    "$$\n",
    "where \n",
    "$$E[dW_t^S,dW_t^v]=\\rho dt$$\n",
    "In risk neutral measure, $\\mu = r - q$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Methodology\n",
    "\n",
    "### 3.1 Notation\n",
    "Option price always requires to work backward. That is because the option price is known exactly at the maturity. As with other schemes, we determine the option price step by step from the maturity $t=K\\tau=T$ to the present time $t=0$. The unit of time being $\\tau$, for example, one day. We simulate $N$ trajectories. In trajectory i, the price of the underlying asset at time $k\\tau$ is denoted as $S_k^{(i)}$. The price of the derivative at time $k\\tau$ is denoted as $C_k$, and the hedge function is $H_k$. We define an optimal hedged portfolio as\n",
    "$$W_k^{(i)} = C_k(S_k^{(i)}) + H_k(S_k^{(i)})S_k^{(i)}$$\n",
    "The one-step change of our portfolio is\n",
    "$$\\Delta W_k^{(i)}= df(k,k+1) C_{k+1}(S_{k+1}^{(i)}) - C_k(S_k^{(i)}) + H_k(S_{k}^{(i)}) (df2(k,k+1) S_{k+1}^{(i)} - S_{k}^{(i)})$$\n",
    "Where $df(k,k+1)$ is the discounted factor from time $k\\tau$ to $(k+1) \\tau$, $df2(k,k+1)$ is the discounted factor considering dividend $e^{-(r-q)(t_{k+1}-t_k)}$\n",
    "\n",
    "### 3.2 Objective\n",
    "The optimal hedged algorithm can be interpreted as the following optimal problem\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{minimize}\\quad & \\quad Var[\\Delta W_k]\\\\\n",
    "\\mbox{subject to}\\quad & \\quad E[\\Delta W_k]=0\n",
    "\\end{align}\n",
    "\n",
    "It means we should try to minimize the realized volatility of hedged portfolio while maintaining the expected value of portfolio unchanged.\n",
    "\n",
    "### 3.3 Basis Functions\n",
    "The original optimization is very difficult to solve. Thus we assume a set of basis function and solved it in such subspace. We use $N_C$and $N_H$ to denote the number of basis functions for price and hedge.\n",
    "\n",
    "\\begin{align}\n",
    "C_k(\\cdot) &= \\sum_{i=0}^{N_C} a_{k,i} A_i(\\cdot)\\\\\n",
    "H_k(\\cdot) &= \\sum_{i=0}^{N_H} b_{k,i} B_i(\\cdot)\n",
    "\\end{align}\n",
    "\n",
    "The basis functions $A_i$ and $B_i$ are priori determined and need not to be identical. The coefficients $a_i$ and $b_i$ can be calibrated by solving the optimal problem.\n",
    "\n",
    "### 3.4 Numerical Solution\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{minimize}\\quad & \\quad \\frac{1}{N} \\sum_{i=1}^N \\Delta W_k^{(i)2}\\\\\n",
    "\\mbox{subject to}\\quad & \\quad \\frac{1}{N} \\sum_{i=1}^N \\Delta W_k^{(i)}=0\n",
    "\\end{align}\n",
    "\n",
    "Denote the discounted forward underlying price change at time $k\\tau$ as\n",
    "\n",
    "$$\\Delta S_k = df2(k,k+1) S_{k+1} - S_k$$\n",
    "\n",
    "Define\n",
    "\n",
    "\\begin{align}\n",
    "Q_k &= \\begin{bmatrix}\n",
    "    -A_{k,1}(S_k^{(1)}) & \\cdots & -A_{k,N_C}(S_k^{(1)}) & B_{k,1}(S_k^{(1)})\\Delta S_k^{(1)}& \\cdots  & B_{k,N_H}(S_k^{(1)})\\Delta S_k^{(1)} \\\\\n",
    "    -A_{k,1}(S_k^{(2)}) & \\cdots & -A_{k,N_C}(S_k^{(2)}) & B_{k,1}(S_k^{(2)})\\Delta S_k^{(2)}& \\cdots  & B_{k,N_H}(S_k^{(1)})\\Delta S_k^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "    -A_{k,1}(S_k^{(N)}) & \\cdots & -A_{k,N_C}(S_k^{(N)}) & B_{k,1}(S_k^{(N)})\\Delta S_k^{(N)}& \\cdots  & B_{k,N_H}(S_k^{(N)})\\Delta S_k^{(N)}\n",
    "    \\end{bmatrix}\\\\\\\\\n",
    "c_k &= (a_{k,1}, \\cdots a_{k,N_C}, b_{k,1}, \\cdots, b_{k,N_H})^T\\\\\\\\\n",
    "v_{k} &= df(k,k+1) C_{k+1}(S_{k+1}^{})\n",
    "\\end{align}\n",
    "\n",
    "As for $v_k$, note that we know the exact value at maturity, which means there is no need to approximate price in terms of basis functions, that is\n",
    "\n",
    "\\begin{align}\n",
    "v_k = \\begin{cases}\n",
    "df(N-1,N)\\ payoff(S_N),\\quad & k=N-1\\\\\n",
    "df(k,k+1)\\ \\sum_{i=1}^{N_C} a_{k+1,i} A_i(S_{k+1}), \\quad & 0<k<N-1\\\\\n",
    "df(0,1)\\ C_1(S_1), \\quad & k=0\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Then, the optimization problem can be expressed as\n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad (v_{k} + Q_k c_k)^T (v_{k} + Q_k c_k)\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T (v_{k}  + Q_k c_k)=0\n",
    "\\end{align}\n",
    "\n",
    "In step k, since we already know the information ($v_{k}$) in step k+1. By canceling the constant term, the optimal problem can be simplified as the following \n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad 2 v_{k}^T Q_k c_k + c_k^T Q_k^T Q_k c_k\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T v_{k}  + 1_{[N\\times1]}^T Q_k c_k=0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Convex Optimization Problem\n",
    "\n",
    "Let us first review the standard form of linear constrained quadratic programming problem:\n",
    "\n",
    "\\begin{align}\n",
    "    \\min_{x} \\quad & \\frac{1}{2} x^T P x + q^T x\\\\\n",
    "    \\mbox{subject to} \\quad &G x \\preceq h\\\\\n",
    "    &A x = b\n",
    "\\end{align}\n",
    "\n",
    "Note that $x^T$ means the transpose of vector x, and $G x \\preceq h$denotes the inequality is taken element-wise over the vectors $G x$ and $h$. The objective function is convex if and only if the matrix $P$ is positive-semidefinite(Hermitian matrix all of whose eigenvalues are nonnegative), which is the realm we concern with.\n",
    "\n",
    "Recall that the constrained optimization problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\arg\\min_{c_k}\\quad & \\quad  v_{k}^T Q_k c_k + \\frac{1}{2}c_k^T Q_k^T Q_k c_k\\\\\n",
    "\\mbox{subject to}\\quad & \\quad 1_{[N\\times1]}^T v_{k}  + 1_{[N\\times1]}^T Q_k c_k=0\n",
    "\\end{align}\n",
    "\n",
    "Correspondingly, we make the connection by letting\n",
    "\n",
    "\\begin{align}\n",
    "    x &= c_k\\\\\n",
    "    P &= Q_k^T Q_k\\\\\n",
    "    q &= Q_k^T v_k\\\\\n",
    "    A &= 1_{[N\\times1]}^T Q_k\\\\\n",
    "    b &= -1_{[N\\times1]}^T v_{k}\n",
    "\\end{align}\n",
    "\n",
    "The hard work is almost over right now. As you would always find, formulating the problem is usually the hard step. Invoking a solver is straightforward.\n",
    "\n",
    "Note that when $k=0$, the degree of freedom of the quadratic problem decreases to 2. Because here the only concerns are price and hedge at time zero (we don't need to project them into a high dimension space). Let $x=[C_0, H_0]^T$\n",
    "\n",
    "\\begin{align}\n",
    "    Q_0 &= \\begin{bmatrix}\n",
    "    -1 & \\Delta S_0^{(1)}\\\\\n",
    "    \\vdots & \\vdots\\\\\n",
    "    -1 & \\Delta S_0^{(N)}\n",
    "    \\end{bmatrix}\\\\\n",
    "    P &= Q_0^T Q_0\\\\\n",
    "    q &= Q_0^T v_0\\\\\n",
    "    A &= 1_{[N \\times 1]}^T Q_0\\\\\n",
    "    b &= -1_{[N \\times 1]}^T v_0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Variance reduction and other methods\n",
    "The rate of convergence of the Monte Carlo simulation is $O\\left(\\max \\left( \\Delta t, \\frac{1}{N_x} \\right)\\right)$. The variance reduction techniques are used to reduce the constant factor corresponding to the Monte Carlo approximation $O \\left(\\frac{1}{N_x}\\right)$. Some of the most used variance reduction techniques are:\n",
    "\n",
    "* Control Variates\n",
    "* Antithetic Variates\n",
    "* Moment Matching\n",
    "\n",
    "In this part we selected antithetic variates and delta-based control variates methods as a supplement to optimal hedged monte carlo simulation.\n",
    "\n",
    "### 4.1 Antithetic variates\n",
    "The main idea of this technique is to look at the asset equation that you aretrying to simulate:\n",
    "$$d S_t^{(1)} = r S_t^{(1)} dt + \\sigma S_t^{(1)} d W_t$$\n",
    "and recognize that sinceztis a standard Brownian motion so will be−ztandthey will have the same exact distribution.  This means that the equation:\n",
    "$$d S_t^{(2)} = r S_t^{(2)} dt - \\sigma S_t^{(2)} d W_t$$\n",
    "will also generate paths of the same asset.\n",
    "The variance depends on the sign of the covariance of $payoff(S_t^{(1)})$ and $payoff(S_t^{(2)})$. It can increase the eventual variance or decrease it, both case do arise. One sufficient condition to insure variance reduction is the monotony of the payoff function. Then, when using both in the calculation of the final Monte Carlo value the variance of the estimate will be reduced.\n",
    "\n",
    "### 4.2 Delta-based control variates\n",
    "Delta hedging can be summarized succinctly in the following way:  Suppose that at time $t= 0$, we receive $C_0$ the price of an option that pays $C_T$ at time T.  The price of this option at any time $t$ is a function $C(t,S)$. Then, if we hold at any moment in time $\\frac{\\partial C}{\\partial S}(t,S) = \\frac{\\partial C_t}{\\partial S}$ units of stock, then we will be able to replicate the payout of this option $C_T$ at time T. This is in theory since of course we cannot trade continuously. So in practice we perform a partial hedge where we only rebalance at some discrete moments in time say $t_1,t_2,\\cdots,t_N$. The replicating strategy can be expressed as follow:\n",
    "$$W(t_i,S_i) = C(t_0,S_0) e^{r(t_i - t_0)} + \\sum_{j=0}^{i} \\Delta(t_j,S_j) ( S_{j+1} e^{-r(t_{j+1} - t_j )} - S_{j})e^{r(t_i - t_j)} = C(t_i,S_i)$$\n",
    "which is similar to the strategy in the optimal hedged Monte Carlo simulation where the only difference is that in OHMC, we use option and delta hedging to replicate the cash flow and here we do the opposite operation. But when implementing the delta-based control variates, we should move the hedging term to the right hand side which make it identical to the OHMC strategy. Note that here we are assumed to know the delta hedging function. It explains a lot why OHMC can reduce the variance.\n",
    "\n",
    "### 4.3 Optimal hedged Monte Carlo simulation\n",
    "**In conclusion, OHMC is just a control variates method with an optimization on top and it is more practical because we do not have an analytical formula for the hedge sensitivity (i.e. delta, gamma, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from cvxopt import matrix, solvers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "risk_free_rate = 0.0319\n",
    "dividend = 0\n",
    "time_to_maturity = 1\n",
    "volatility = 0.2\n",
    "strike = 100\n",
    "stock_price = 100\n",
    "V0 = 0.010201\n",
    "kappa = 6.21\n",
    "theta = 0.019\n",
    "xi = 0.61\n",
    "rho = -0.7\n",
    "\n",
    "n_trails = 1000\n",
    "n_steps = 200\n",
    "func_list = [lambda x: x**0, lambda x: x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MonteCarlo import MonteCarlo   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_matrix = mc.simulate(n_trails=n_trails,n_steps=n_steps,boundaryScheme=\"absorption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.MCPricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.BSDeltaHedgedPricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.OHMCPricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices = mc.pricing(func_list=func_list)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hedges = mc.hedging()\n",
    "print(hedges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Methods Comparison\n",
    "\n",
    "In this part, we discuss the performance of OHMC and regular MC. The underlying stochastic process is Heston model. In the following, we compare the absolute error with respect to the Black-Scholes price corresponding to trajactories number and runtime. The result is displayed by scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_comparison(n_trails,n_steps,underlying_process=\"geometric brownian motion\"):\n",
    "    if(underlying_process==\"geometric brownian motion\"):\n",
    "        mc = MonteCarlo(stock_price,strike,time_to_maturity,risk_free_rate,dividend,volatility)\n",
    "        theoretical_value = mc.BlackScholesPricer()\n",
    "    elif(underlying_process==\"Heston model\"):\n",
    "        mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "        theoretical_value = 6.8061\n",
    "    \n",
    "    # black scholes\n",
    "    bs_start = timeit.default_timer()\n",
    "    bs_price = mc.BlackScholesPricer('c')\n",
    "    bs_sde_estimate = 'NA'\n",
    "    bs_rmse = 'NA'\n",
    "    bs_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC\n",
    "    rmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    rmc_price = mc.MCPricer('c')\n",
    "    rmc_sde_estimate = mc.standard_error()\n",
    "    rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC with antithetic variates\n",
    "    rmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    rmc_anti_price = mc.MCPricer('c')\n",
    "    rmc_anti_sde_estimate = mc.standard_error()\n",
    "    rmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # Delta-based MC\n",
    "    dbmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    dbmc_price = mc.BSDeltaHedgedPricer('c')\n",
    "    dbmc_sde_estimate = mc.standard_error()\n",
    "    dbmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    dbmc_end = timeit.default_timer()\n",
    "    \n",
    "    # Delta-based MC with antithetic variates\n",
    "    dbmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps)\n",
    "    dbmc_anti_price = mc.BSDeltaHedgedPricer('c')\n",
    "    dbmc_anti_sde_estimate = mc.standard_error()\n",
    "    dbmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    dbmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC\n",
    "    ohmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    ohmc_price = mc.OHMCPricer('c')\n",
    "    ohmc_sde_estimate = \"NA\"\n",
    "    ohmc_rmse = 'NA'\n",
    "    ohmc_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC with antithetic varietes\n",
    "    ohmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    ohmc_anti_price = mc.OHMCPricer('c')\n",
    "    ohmc_anti_sde_estimate = \"NA\"\n",
    "    ohmc_anti_rmse = 'NA'\n",
    "    ohmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    bs_runtime = bs_end - bs_start\n",
    "    rmc_runtime = rmc_end - rmc_start\n",
    "    dbmc_runtime = dbmc_end - dbmc_start\n",
    "    ohmc_runtime = ohmc_end-ohmc_start\n",
    "    rmc_anti_runtime = rmc_anti_end - rmc_anti_start\n",
    "    dbmc_anti_runtime = dbmc_anti_end - dbmc_anti_start\n",
    "    ohmc_anti_runtime = ohmc_anti_end-ohmc_anti_start\n",
    "    \n",
    "    bs_err = np.abs(bs_price - theoretical_value)\n",
    "    rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "    dbmc_err = np.abs(dbmc_price - theoretical_value)\n",
    "    ohmc_err = np.abs(ohmc_price - theoretical_value)\n",
    "    rmc_anti_err = np.abs(rmc_anti_price - theoretical_value)\n",
    "    dbmc_anti_err = np.abs(dbmc_anti_price - theoretical_value)\n",
    "    ohmc_anti_err = np.abs(ohmc_anti_price - theoretical_value)\n",
    "    \n",
    "    \n",
    "    result = {\"method\":[\"Black Scholes\",\"MC\",\"antithetic MC\",\"DBMC\",\"antithetic DBMC\",\"OHMC\",\"antithetic OHMC\"],\n",
    "              \"runtime\":[bs_runtime,rmc_runtime,rmc_anti_runtime,dbmc_runtime,dbmc_anti_runtime,\n",
    "                         ohmc_runtime,ohmc_anti_runtime],\n",
    "              \"err\":[bs_err,rmc_err,rmc_anti_err,dbmc_err,dbmc_anti_err,ohmc_err,ohmc_anti_err], \n",
    "              \"standard err estimate\":[bs_sde_estimate,rmc_sde_estimate,rmc_anti_sde_estimate,dbmc_sde_estimate,\n",
    "                              dbmc_anti_sde_estimate,ohmc_sde_estimate,ohmc_anti_sde_estimate],\n",
    "              \"root mean square error\":[bs_rmse, rmc_rmse, rmc_anti_rmse, dbmc_rmse, dbmc_anti_rmse, ohmc_rmse, ohmc_anti_rmse],\n",
    "              \"n_trails\":[n_trails]*7,\n",
    "              \"n_steps\":[n_steps]*7}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_trails_list = np.arange(100,1000,500)\n",
    "n_steps_list = np.arange(50,200,50)\n",
    "performance_df = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "    for n_steps in n_steps_list:\n",
    "        print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "        new_df = pd.DataFrame(performance_comparison(n_trails,n_steps,underlying_process=\"Heston model\"))\n",
    "        performance_df = pd.concat((performance_df,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_efficiency_df = performance_df.set_index(['method','n_steps','n_trails']).sort_index()\n",
    "sorted_efficiency_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Variance Reduction Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thie section, we test more case and visualize the empirical error. Note that we do not concern Delta-based MC simulation since we cannot convert it to a matrix form, as a result, the method involes for-loop which is not efficient (see the form above). Moreover, the hypothesis which we know the delta hedge function is not realistic in practice. The result shows as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_comparison2(n_trails,n_steps,underlying_process=\"geometric brownian motion\"):\n",
    "    if(underlying_process==\"geometric brownian motion\"):\n",
    "        mc = MonteCarlo(stock_price,strike,time_to_maturity,risk_free_rate,dividend,volatility)\n",
    "        theoretical_value = mc.BlackScholesPricer()\n",
    "    elif(underlying_process==\"Heston model\"):\n",
    "        mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "        theoretical_value = 6.8061\n",
    "    \n",
    "    # black scholes\n",
    "    bs_start = timeit.default_timer()\n",
    "    bs_price = mc.BlackScholesPricer('c')\n",
    "    bs_sde_estimate = 'NA'\n",
    "    bs_rmse = 'NA'\n",
    "    bs_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC\n",
    "    rmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    rmc_price = mc.MCPricer('c')\n",
    "    rmc_sde_estimate = mc.standard_error()\n",
    "    rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_end = timeit.default_timer()\n",
    "    \n",
    "    # regular MC with antithetic variates\n",
    "    rmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    rmc_anti_price = mc.MCPricer('c')\n",
    "    rmc_anti_sde_estimate = mc.standard_error()\n",
    "    rmc_anti_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "    rmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC\n",
    "    ohmc_start = timeit.default_timer()\n",
    "    mc.simulate(n_trails,n_steps)\n",
    "    ohmc_price = mc.OHMCPricer('c')\n",
    "    ohmc_sde_estimate = \"NA\"\n",
    "    ohmc_rmse = 'NA'\n",
    "    ohmc_end = timeit.default_timer()\n",
    "    \n",
    "    # OHMC with antithetic varietes\n",
    "    ohmc_anti_start = timeit.default_timer()\n",
    "    mc.simulate(int(n_trails/2),n_steps,antitheticVariates=True)\n",
    "    ohmc_anti_price = mc.OHMCPricer('c')\n",
    "    ohmc_anti_sde_estimate = \"NA\"\n",
    "    ohmc_anti_rmse = 'NA'\n",
    "    ohmc_anti_end = timeit.default_timer()\n",
    "    \n",
    "    bs_runtime = bs_end - bs_start\n",
    "    rmc_runtime = rmc_end - rmc_start\n",
    "    \n",
    "    ohmc_runtime = ohmc_end-ohmc_start\n",
    "    rmc_anti_runtime = rmc_anti_end - rmc_anti_start\n",
    "    \n",
    "    ohmc_anti_runtime = ohmc_anti_end-ohmc_anti_start\n",
    "    \n",
    "    bs_err = np.abs(bs_price - theoretical_value)\n",
    "    rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "    \n",
    "    ohmc_err = np.abs(ohmc_price - theoretical_value)\n",
    "    rmc_anti_err = np.abs(rmc_anti_price - theoretical_value)\n",
    "    \n",
    "    ohmc_anti_err = np.abs(ohmc_anti_price - theoretical_value)\n",
    "    \n",
    "    \n",
    "    result = {\"method\":[\"Black Scholes\",\"MC\",\"antithetic MC\",\"OHMC\",\"antithetic OHMC\"],\n",
    "              \"runtime\":[bs_runtime,rmc_runtime,rmc_anti_runtime,\n",
    "                         ohmc_runtime,ohmc_anti_runtime],\n",
    "              \"err\":[bs_err,rmc_err,rmc_anti_err,ohmc_err,ohmc_anti_err], \n",
    "              \"standard err estimate\":[bs_sde_estimate,rmc_sde_estimate,rmc_anti_sde_estimate,\n",
    "                                       ohmc_sde_estimate,ohmc_anti_sde_estimate],\n",
    "              \"root mean square error\":[bs_rmse, rmc_rmse, rmc_anti_rmse, ohmc_rmse, ohmc_anti_rmse],\n",
    "              \"n_trails\":[n_trails]*5,\n",
    "              \"n_steps\":[n_steps]*5}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_trails_list = np.arange(100,10000,500)\n",
    "# n_steps_list = np.arange(50,200,50)\n",
    "performance_df2 = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "#     for n_steps in n_steps_list:\n",
    "    print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "    new_df = pd.DataFrame(performance_comparison2(n_trails,n_steps,underlying_process=\"Heston model\"))\n",
    "    performance_df2 = pd.concat((performance_df2,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "mc_trails = performance_df2[performance_df2[\"method\"]==\"MC\"][\"n_trails\"]\n",
    "mc_err = performance_df2[performance_df2[\"method\"]==\"MC\"][\"err\"]\n",
    "ax.plot(mc_trails,mc_err,label=\"regular MC\")\n",
    "\n",
    "anti_mc_trails = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"n_trails\"]\n",
    "anti_mc_err = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"err\"]\n",
    "ax.plot(anti_mc_trails,anti_mc_err,label=\"antithetic regular MC\")\n",
    "\n",
    "ohmc_trails = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"n_trails\"]\n",
    "ohmc_err = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"err\"]\n",
    "ax.plot(ohmc_trails,ohmc_err,label=\"OHMC\")\n",
    "\n",
    "anti_ohmc_trails = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"n_trails\"]\n",
    "anti_ohmc_err = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"err\"]\n",
    "ax.plot(anti_ohmc_trails,anti_ohmc_err,label=\"antithetic OHMC\")\n",
    "\n",
    "ax.legend()\n",
    "plt.xlabel(\"n_trails\")\n",
    "plt.ylabel(\"err\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Runtime Efficiency Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "mc_runtime = performance_df2[performance_df2[\"method\"]==\"MC\"][\"runtime\"]\n",
    "mc_err = performance_df2[performance_df2[\"method\"]==\"MC\"][\"err\"]\n",
    "ax.scatter(mc_runtime,mc_err,label=\"regular MC\")\n",
    "\n",
    "anti_mc_runtime = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"runtime\"]\n",
    "anti_mc_err = performance_df2[performance_df2[\"method\"]==\"antithetic MC\"][\"err\"]\n",
    "ax.scatter(mc_runtime,mc_err,label=\"antithetic regular MC\")\n",
    "\n",
    "ohmc_runtime = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"runtime\"]\n",
    "ohmc_err = performance_df2[performance_df2[\"method\"]==\"OHMC\"][\"err\"]\n",
    "ax.scatter(ohmc_runtime,ohmc_err,label=\"OHMC\")\n",
    "\n",
    "anti_ohmc_runtime = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"runtime\"]\n",
    "anti_ohmc_err = performance_df2[performance_df2[\"method\"]==\"antithetic OHMC\"][\"err\"]\n",
    "ax.scatter(ohmc_runtime,ohmc_err,label=\"antithetic OHMC\")\n",
    "\n",
    "ax.legend()\n",
    "plt.xlabel(\"runtime\")\n",
    "plt.ylabel(\"err\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Conclusion\n",
    "\n",
    "From the test, one can see OHMC reduce the variance considerably, which make it more appreciable when number of trails is limited. For example, if we can only make trails less than 1000, OHMC is definite better than regular MC. However the runtime efficiency is similar based our observation. It seems slightly stable than regular MC, but still not enough to affirm that. As for the antithetic variates' version, there is no promotion in time efficiency and the variance reduction effect is valid only when number of trajectories is small enough and not gauranteed. Therefore, the antithetic variates method is not effective enough, the delta-based method is neither time efficient nor practical. At last, we highly recommand the optimal hedged Monte Carlo simulation as it is efficient, accurate and compatible to most of the stochastic process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Boundary Scheme Test\n",
    "\n",
    "Five kinds of boundary scheme:\n",
    "\n",
    "* absorption\n",
    "* reflection\n",
    "* Higham and Mao\n",
    "* partial truncation\n",
    "* full truncation\n",
    "\n",
    "We used Euler discretization schemes as presented in Table 1 of the paper \n",
    "\n",
    "Lord, Roger, Remmert Koekkoek, and Dick Van Dijk. A comparison of biased simulation schemes for stochastic volatility models. Quantitative Finance 10.2 (2010): 177-194.\n",
    "\n",
    "https://www.ssoar.info/ssoar/bitstream/handle/document/22127/ssoar-2010-02-lord_et_al-a_comparison_of_biased_simulation.pdf?sequence=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boundary_scheme_comparison(n_trails,n_steps,boundarySchemes):\n",
    "    simulation_start = timeit.default_timer()\n",
    "    mc = MonteCarlo(S0=stock_price,K=strike,T=time_to_maturity,r=risk_free_rate,q=dividend,sigma=volatility,\n",
    "                kappa=kappa,theta=theta,xi=xi,rho=rho,V0=V0,underlying_process=\"Heston model\")\n",
    "    simulation_end = timeit.default_timer()\n",
    "    theoretical_value = 6.8061\n",
    "    \n",
    "    se_estimate_list = []\n",
    "    rmse_list = []\n",
    "    abs_err_list = []\n",
    "    runtime_list = []\n",
    "    \n",
    "    for boundaryScheme in boundarySchemes:\n",
    "        # regular MC\n",
    "        rmc_start = timeit.default_timer()\n",
    "        mc.simulate(n_trails,n_steps,boundaryScheme=boundaryScheme)\n",
    "        rmc_price = mc.MCPricer('c')\n",
    "        rmc_end = timeit.default_timer()\n",
    "        \n",
    "        rmc_se_estimate = mc.standard_error()\n",
    "        rmc_rmse = np.sqrt(np.mean((mc.value_results - theoretical_value)**2))\n",
    "        rmc_runtime = rmc_end-rmc_start + simulation_end - simulation_start\n",
    "        rmc_err = np.abs(rmc_price - theoretical_value)\n",
    "        se_estimate_list.append(rmc_se_estimate)\n",
    "        rmse_list.append(rmc_rmse)\n",
    "        abs_err_list.append(rmc_err)\n",
    "        runtime_list.append(rmc_runtime)\n",
    "        \n",
    "    result = {\"boundary scheme\": boundarySchemes,\n",
    "              \"n_trials\": [n_trails]*len(boundarySchemes),\n",
    "              \"n_steps\": [n_steps]*len(boundarySchemes),\n",
    "              \"runtime\": runtime_list,\n",
    "              \"abs err\": abs_err_list,\n",
    "              \"root mean square err\": rmse_list,\n",
    "              \"standard err estimate\": se_estimate_list\n",
    "             }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_trails_list = np.arange(100,1000,500)\n",
    "n_steps_list = np.arange(50,200,50)\n",
    "boundarySchemes = [\"absorption\", \"reflection\", \"Higham and Mao\", \"partial truncation\", \"full truncation\"]\n",
    "boundary_scheme_df = pd.DataFrame()\n",
    "for n_trails in n_trails_list:\n",
    "    for n_steps in n_steps_list:\n",
    "        print(\"n_trials: {}; n_steps: {}\".format(n_trails,n_steps))\n",
    "        new_df = pd.DataFrame(boundary_scheme_comparison(n_trails,n_steps,boundarySchemes))\n",
    "        boundary_scheme_df = pd.concat((boundary_scheme_df,new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_boundary_scheme_df = boundary_scheme_df.set_index(['boundary scheme','n_steps','n_trials']).sort_index()\n",
    "sorted_boundary_scheme_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the above form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundary_scheme_df.groupby(\"boundary scheme\").apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the absolute error, Higham and Mao's scheme works the best and the reflection scheme performs the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
